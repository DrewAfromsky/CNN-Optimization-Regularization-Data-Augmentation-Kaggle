Optimizers: 
- numpy implementation of SGD with Momentum, RMSprop and Adam.

Regularization:
- To efficienlty train a good neural network, using a suitable optimizer is important but not enough. Other important considerations include how to select good initialization values for ANN parameters, and how to avoid overfitting. 
- Dropout and Batch Normalization. Implemented in numpy.

Convolutional Neural Network (CNN):
- In contrast to the Multi-Layer Perceptron (ML) or fully-connected (FC) nets, Convolutional Neural Netwworks are a more powerful tool often used in the field of computer vision. Create a CNN using Tensorflow.

Data Augmentation:
- Data augmentation is very useful for CNNs. It can enrich the collected datasets by enlarging them using the operations on the original data samples. It can promote the performance of networks. Create a data generator which does several augmentations.

Bottle Kaggle Competition:
- In-class Kaggle competition and compete with your classmates on the "bottle classification problem". You need to keep updating your CNN in iterations to get the best possible result. Kaggle will enable you to observe the progress made by students in the class. You can use any/all of the deep learning modelling techiques (e.g. regularization, optimization) to get the best possible performance. TensorFlow 1.13 used to build model.
