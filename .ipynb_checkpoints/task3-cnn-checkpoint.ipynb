{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2 - Task 3: Convolutional Neural Network (CNN)\n",
    "\n",
    "In this task, you are going to first practice the forward/backward propagation of the convolutional operations with Numpy. After that, we will introduce TensorFlow with which you'll create your CNN model for an image classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs:\n",
    "This is one of the good posts describing CNNs:\n",
    "\n",
    "[https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "\n",
    "Convolutional neural networks (CNNs) are a type of neural networks which is highly effective for image processing. \n",
    "\n",
    "Remember when we build an MLP model, each input is multiplied by its own weights. When the input dimension or the first layer is too large, we will need a giant matrix to store our weights. This could easily become a problem in image processing since the dimension of a vectorized image could easily exceed 1000 (consider CIFAR-10 which has images of shape 32Ã—32=1024, yet the resolution is so low). \n",
    "\n",
    "In CNN, the weights can be shared: the same filter (also known as 'weights' or 'kernel') moves over the input, and at each position an output value is calculated. This means the same weights are used by the entire input, therefore saving a lot of memory.\n",
    "\n",
    "![Illustration of the CNN](./utils/notebook_images/task3_1.jpg)\n",
    "Image source: [here](https://developer.apple.com/library/content/documentation/Performance/Conceptual/vImage/ConvolutionOperations/ConvolutionOperations.html)\n",
    "\n",
    "__Convolution:__  In the picture above, the input is a 7-by-7 image, and the filter is shown as a blue 3-by-3 grid. The filter overlaps with the top-left corner of the input, and we perform an element-wise multiplication followed by a summation, then put the sum into the output matrix. The filter then moves several pixels right, covering a new input area so a new sum can be derived.\n",
    "\n",
    "__Training:__ One thing to remember is that there would be a lot of filters for each layer in a CNN, and the goal of training is to find the best filters for your task. Each filter tries to capture one specific feature. Typically, in the first convolutional layer which directly looks at your input, the filters try to capture information about color and edges which we know as local features; in higher layers, due to the effect of max-pooling, the receptive-fields of filters becomes large so more global and complex features can be detected. \n",
    "\n",
    "__Architecture:__ For classification tasks, a CNN usually starts with convolution followed by max-pooling. After that, the feature maps will be flattened so that we could append fully connected layers. Common activation functions include ReLu, ELU in the convolution layers, and softmax in the fully connected layers (to calculate the classification scores).\n",
    "\n",
    "---\n",
    "\n",
    "### Terminology\n",
    "\n",
    "* __Convolution__: element-wise multiplication followed by summation of your input and one of your filters in the CNN context.\n",
    "* __Filter/kernel/weights__: a grid or a set of grids typically smaller than your input size that moves over the input space to generate output. Each filter captures one type of feature.\n",
    "* __Feature/feature maps__: the output of a hidden layer. Think of it as another representation of your data. \n",
    "* __Pooling__: an downsampling operation that joins local information together, so the higher layers' receptive fields can be bigger. The most seen pooling operation is max-pooling, which outputs the maximum of all values inside the pool.\n",
    "* __Flatten__: a junction between convolution layers and fully connected layers. Used to turn 2-D feature maps into 1-D. For tasks such as image segmentation where the output also needs to be 2-D, this won't be used.\n",
    "* __Border mode__: usually refers to 'VALID' or 'SAME'. Under 'VALID' mode, only when the filter and the input fully overlap can a convolution be conducted; under 'SAME' mode, the output size is the same as the input size (only when the stride is 1), and when the filter and the input don't fully overlap (happens at the edge/corner of input) we pad zeroes (or other designated numbers) and then do convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Applications/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Applications/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Applications/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Applications/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Applications/anaconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting a sense of convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d feedforward\n",
    "\n",
    "Implement a Numpy naive 2-D convolution feedforward function. We ask you to simply do the element-wise multiplication and summation. Also, don't need to worry about the efficiency of your function. Use loops as many as you like.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __conv2d_forward__ in __utils/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your convolution function. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5,5,3) into shape (5,5,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-750ee2c2a56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0myour_feedforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your feedforward result (size :{}) is: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_feedforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Fall_2019/ECBM_4040-Neural_Networks_and_Deep_Learning/E4040_2019Fall_assignments/assignment_2/utils/layer_funcs.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(x, w, b, pad, stride)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_filt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5,5,3) into shape (5,5,5)"
     ]
    }
   ],
   "source": [
    "from utils.layer_funcs import conv2d_forward\n",
    "\n",
    "# Set test parameters.\n",
    "# x_shape = (2, 5, 5, 3) #(batch, height, width, channels)\n",
    "# w_shape = (3, 3, 3, 5) #(filter_height, filter_width, channels, num_of_filters)\n",
    "x_shape = (2, 4, 4, 3)\n",
    "w_shape = (3, 4, 4, 3)\n",
    "\n",
    "channels = w_shape[-1]\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=channels)\n",
    "pad = 1\n",
    "stride = 2\n",
    "your_feedforward = conv2d_forward(x, w, b, pad, stride)\n",
    "\n",
    "print(\"Your feedforward result (size :{}) is: \".format(your_feedforward.shape))\n",
    "print(your_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d backpropagation (optional, bonus +10 points)\n",
    "\n",
    "<p style=\"color:red\">This function is optional, but a bonus 10 points will be given if you solve it correctly.</p>\n",
    "\n",
    "Implement a Numpy naive 2-D convolution backpropagation function. Again, don't worry about the efficiency.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __conv2d_backward__ in __utils/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your backpropagation. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.layer_funcs import conv2d_backward\n",
    "# Set test parameters. Please don't change it.\n",
    "np.random.seed(234)\n",
    "d_top = np.random.normal(size=your_feedforward.shape)\n",
    "your_dw, your_db, d_w_shape = conv2d_backward(d_top, x, w, b, pad, stride)\n",
    "\n",
    "print(\"Your weights' gradients result (size :{}) is: \".format(d_w_shape))\n",
    "print(your_dw)\n",
    "print(\"Your biases' gradients result is: \")\n",
    "print(your_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max pool feedforward\n",
    "\n",
    "Implement a Numpy naive max pool feedforward function. We ask you to simply find the max in your pooling window. Also, don't need to worry about the efficiency of your function. Use loops as many as you like.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __max_pool_forward__ in __utils/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your max pool function. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.layer_funcs import max_pool_forward\n",
    "\n",
    "# Set test parameters.\n",
    "x_shape = (2, 5, 5, 3) #(batch, height, width, channels)\n",
    "x = np.linspace(-0.5, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_size = 2\n",
    "stride = 2\n",
    "\n",
    "your_feedforward = max_pool_forward(x, pool_size, stride)\n",
    "\n",
    "print(\"Your feedforward result (size :{}) is: \".format(your_feedforward.shape))\n",
    "print(your_feedforward)\n",
    "###########################################\n",
    "#          Only for instructors           #\n",
    "###########################################\n",
    "# Check the answer by tensorflow nn.max_pool\n",
    "X_tf = tf.placeholder(tf.float32, shape=x_shape)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "feedforward = tf.nn.max_pool(X_tf, [1, pool_size, pool_size, 1], [1, stride, stride, 1], padding='VALID')\n",
    "with tf.Session() as sess:\n",
    "     tf_feedforward = sess.run(feedforward, feed_dict={X_tf: x})\n",
    "\n",
    "## Print validation result\n",
    "print(\"Is your feedforward correct? {}\".format(np.allclose(your_feedforward, tf_feedforward)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max pool backpropogation (optional, bonus +10 points)\n",
    "\n",
    "<p style=\"color:red\">This function is optional, but a bonus 10 points will be given if you solve it correctly.</p>\n",
    "\n",
    "Implement a Numpy naive max pooling backpropagation function. Again, don't worry about the efficiency.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __max_pool_backward__ in __utils/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your backpropagation. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.layer_funcs import max_pool_backward\n",
    "\n",
    "# Set test parameters. Please don't change it.\n",
    "np.random.seed(234)\n",
    "dout = np.random.normal(size=your_feedforward.shape)\n",
    "dx = max_pool_backward(dout, x, pool_size, stride)\n",
    "\n",
    "print(\"Your inputs' gradients result (size :{}) is: \".format(dx.shape))\n",
    "print(dx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: TensorFlow CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will construct the CNN in TensorFlow. To be more specific, we are going to implement a CNN similar to the LeNet structure.\n",
    "\n",
    "Tensorflow offers many useful resources and functions which help developers build the net in a high-level fashion, such as functions in the `layer` module. However, we will build the network **by ourself** for this homework for better understanding. By utilizing functions in `tf.nn` that exist for Neural Network structuring and training, we can build out our own layers and network modules rather quickly.\n",
    "\n",
    "Also, we will introduce a visualization tool called Tensorboard. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data that pass through it.\n",
    "\n",
    "Resources and References: <br>\n",
    "* [TensorBoard: Visualizing Learning](https://www.tensorflow.org/get_started/summaries_and_tensorboard)<br>\n",
    "* [Convolutional Neural Networks (LeNet) - DeepLearning 0.1 documentation](http://deeplearning.net/tutorial/lenet.html)<br>\n",
    "* [LeNet-5, convolutional neural networks](http://yann.lecun.com/exdb/lenet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick guide for Tensorboard\n",
    "\n",
    "Tensorboard is a powerful tool provided by TensorFlow. It allows developers to check their graph and trend of parameters. This guide will give you a basic under standing on how to set up Tensorboard graph in your code, start tensorboard on your local machine/GCP instance and how to access the interface.\n",
    "\n",
    "For complete instructions, check the official guide on Tensorflow web site [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n",
    "\n",
    "### How to start tensorboard\n",
    "\n",
    "#### Local\n",
    "\n",
    "To start your Tensorboard on your local machine, you need to specify a log directory for the service to fetch the graph. For example, in your command line, type:\n",
    "\n",
    "```shell\n",
    "$ tensorboard --logdir=\"~/log\"\n",
    "```\n",
    "\n",
    "Then, Tensorboard will start running. By default, it will be running on port 6006:\n",
    "\n",
    "``` shell\n",
    "TensorBoard 1.8.0 at http://localhost:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "Make sure Tensorboard is running, you can visit http://localhost:6006 In your browser and you should be able to see the main page of Tensorboard. If the page is shown as below, it means Tensorboard is running correctly. The report is due to lack of event file, but we can just leave it there for now.\n",
    "\n",
    "![Tensorboard_1](./utils/notebook_images/task3_2_1.png)\n",
    "\n",
    "#### GCP\n",
    "\n",
    "To set up the Tensorboard on GCP is the same as above. However, we're not able to check the Tensorboard UI directly through our browser. In order to visit the page through our local browser, we should link the port of our local machine to the port on GCP. It is similar to what we did previously for Jupyter Notebook.\n",
    "\n",
    "In the command line on your local machine, type:\n",
    "\n",
    "```shell\n",
    "$ gcloud compute ssh --ssh-flag=\"-L 9999:localhost:9999 -L 9998:localhost:6006\" \"ecbm4040@YOUR_INSTANCE\"\n",
    "```\n",
    "\n",
    " This will bind your port of your local machine to the port on GCP instance. In this case, your local port 9999 is binded with 9999 on GCP, while local port 9998 is binded with 6006 on GCP. You can change whatever port you like as long as it does not confilct with your local services.\n",
    "\n",
    "After connecting to GCP using the command, you will be able to see the result page.\n",
    "\n",
    "\n",
    "\n",
    "### Export Tensorboard events into log directory\n",
    "\n",
    "To generate data files for Tensorboard, we should use class `tf.summary.FileWriter`. This class will save your network graph sturcuture and all the variable summary. \n",
    "\n",
    "For example, in `cnn.py `, the file writer will save the graph and the summary into a directory based on the current timestamp. Here is the code snippet:\n",
    "\n",
    "```python\n",
    "cur_model_name = 'lenet_{}'.format(int(time.time()))\n",
    "# ...\n",
    "\n",
    "# set up summary writer for tensorboard\n",
    "merge = tf.summary.merge_all()\t# merge all the summary for variables for execution\n",
    "writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "```\n",
    "\n",
    "The following code will save all the parameter summary and marked with iteration_total. These data will be displayed in the Tensorboard later on.\n",
    "\n",
    "```python\n",
    "# ... previous code ...\n",
    "# ...\n",
    "\t\t\t\tif iter_total % 100 == 0:\n",
    "                    # do validation\n",
    "                    valid_eve, merge_result = sess.run([eve, merge], feed_dict={xs: X_val, ys: y_val})\n",
    "                    valid_acc = 100 - valid_eve * 100 / y_val.shape[0]\n",
    "                    if verbose:\n",
    "                        print('{}/{} loss: {} validation accuracy : {}%'.format(\n",
    "                            batch_size * (itr + 1),\n",
    "                            X_train.shape[0],\n",
    "                            cur_loss,\n",
    "                            valid_acc))\n",
    "\n",
    "                    # save the merge result summary\n",
    "                    writer.add_summary(merge_result, iter_total)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Check the graph and summary in Tensorboard\n",
    "\n",
    "After executing the program once, you should able to see the graph displayed in the tensorboard. You can zoom in or zoom out or click into the layer block to check all the variables and tensor operations.\n",
    "\n",
    "![Tensorboard_2](./utils/notebook_images/task3_2_2.png)\n",
    "\n",
    "Also, you may able to check the trend of the variables and the distribution of those in Scalar, Distributions and Histograms. You may explore the tensorboard by yourself and take advantage to it for debuging the nerwork structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> You will try to achieve your own CNN model that has similar structure to LeNet, show the model graph in tensorboard, and get a model with __90% or higher accuracy__ using the data we provide you.\n",
    "\n",
    "An example code is included in __utils/neuralnets/cnn/LeNet_model.py__. This sample is used as a guide line for how to build a Neural Net model in Tensorflow. Feel free to utilize or change the code we give you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "<p style=\"color:red\">The following cell loads the data for you. You don't need to change them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw Fashion Mnist data.\n",
    "img_cols = 28\n",
    "img_rows = 28\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "# Data organizations:\n",
    "# Train data: 59000 samples from original train set: 1~59000\n",
    "# Validation data: 1000 samples from original train set: 59000~60000\n",
    "num_training = 59000\n",
    "num_validation = 1000\n",
    "X_train = X_train.reshape(-1, img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(-1, img_rows, img_cols, 1)\n",
    "X_val = X_train[num_training:num_training+num_validation, :]\n",
    "y_val = y_train[num_training:num_training+num_validation]\n",
    "X_train = X_train[0:num_training, :]\n",
    "y_train = y_train[0:num_training]\n",
    "\n",
    "mean_image = np.mean(X_train, axis=0).astype(np.float32)\n",
    "X_train = X_train.astype(np.float32) - mean_image\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuralnets.cnn.LeNet_model import training\n",
    "tf.reset_default_graph()\n",
    "training(X_train, y_train, X_val, y_val, \n",
    "         conv_featmap=[6],\n",
    "         fc_units=[84],\n",
    "         conv_kernel_size=[5],\n",
    "         pooling_size=[2],\n",
    "         l2_norm=0.01,\n",
    "         seed=235,\n",
    "         learning_rate=1e-4,\n",
    "         epoch=20,\n",
    "         batch_size=295,\n",
    "         verbose=False,\n",
    "         pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the model structure graph\n",
    "We provide the code to integrate the tensorboard graph into jupyter notebook. You can run the code below to check the graph structure. However, for full functions of tensorboard, you should still use tensorboard through your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the graph\n",
    "from utils.neuralnets.cnn.jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model/lenet_example.meta')\n",
    "    graph = tf.get_default_graph()\n",
    "    show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span>\n",
    "1. Complete the your own CNN that derives from the LeNet structure in __utils/neuralnets/cnn/my_LeNet_model.py__ with at least **90%** accuracy.\n",
    "2. Print out the training process and the best validation accuracy, save the `.meta` model in __model/__ folder.\n",
    "3. Attatch a screen shot of your tensorboard graph in the markdown cell below. Double click the cell and replace the example image with your own image. Here is a [Markdown Cheetsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#images) that may also help.\n",
    "\n",
    "__Hint__: \n",
    "1. You can copy and edit the code from `LeNet_model.py`\n",
    "2. The techniques in task-1 and task-2 will help. Check the corresponding functions in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuralnets.cnn.my_LeNet_model import my_training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: my_training(X_train, y_train, X_val, y_val, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> replace the example image with your own tensorboard graph screenshot.\n",
    "![Tensorboard_2](./utils/notebook_images/task3_2_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the graph if you want\n",
    "from utils.neuralnets.cnn.jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the graph if you want\n",
    "from utils.neuralnets.cnn.jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model/lenet_best.meta')\n",
    "    graph = tf.get_default_graph()\n",
    "    show_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTF113",
   "language": "python",
   "name": "envtf113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
